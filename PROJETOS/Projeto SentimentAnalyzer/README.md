# üìä Projeto SentimentAnalyzer

Este projeto tem como objetivo analisar o **sentimento** de um texto utilizando **modelos de aprendizado profundo** baseados em **transformers**, por meio da biblioteca ü§ó `transformers` da Hugging Face.

O usu√°rio pode escolher entre **tr√™s modelos distintos** de an√°lise de sentimentos, todos treinados com bases de dados diferentes e voltados para contextos espec√≠ficos, como multil√≠ngue, espanhol e ingl√™s informal (tweets).

---

## üéØ Objetivo do Projeto

O `SentimentAnalyzer` permite que voc√™:

- Escolha entre 3 modelos de an√°lise de sentimentos.
- Analise textos em diferentes idiomas ou estilos (formal/informal).
- Interprete o sentimento com **√≠cones emoji** para facilitar a compreens√£o.
- Visualize o modelo utilizado, a sa√≠da bruta, a confian√ßa e a interpreta√ß√£o do sentimento.

---

## üß† Modelos Dispon√≠veis

### 1Ô∏è‚É£ `nlptown/bert-base-multilingual-uncased-sentiment`

- üìÖ Ano: Lan√ßado em 2020.
- üåê Multil√≠ngue: funciona com textos em **v√°rios idiomas** (inclusive portugu√™s).
- ü§ñ Baseado no **BERT-base**.
- üìö Treinado com avalia√ß√µes de lugares como restaurantes e hot√©is (Yelp, Amazon, TripAdvisor).
- üî¢ Classifica√ß√£o de 1 a 5 estrelas.
- üóÉÔ∏è Base de dados: aproximadamente 150 mil avalia√ß√µes.
- ‚öôÔ∏è Ideal para reviews e feedbacks de usu√°rios.

### 2Ô∏è‚É£ `pysentimiento/robertuito-sentiment-analysis`

- üìÖ Ano: 2021.
- üá™üá∏ Focado em textos em **espanhol**.
- üß± Baseado no **RoBERTuito** (varia√ß√£o do RoBERTa para espanhol).
- üìö Treinado com milh√µes de tweets em espanhol.
- üî§ Labels: `POS` (positivo), `NEG` (negativo), `NEU` (neutro).
- ü§ù √ìtimo para redes sociais e comunica√ß√£o informal em espanhol.

### 3Ô∏è‚É£ `finiteautomata/bertweet-base-sentiment-analysis`

- üìÖ Ano: 2020.
- üåê Focado em **ingl√™s informal**, especialmente **tweets**.
- üê¶ Baseado no **BERTweet**, um modelo treinado com **850 milh√µes de tweets**.
- üìä Labels: `POS`, `NEG`, `NEU`.
- üöÄ Excelente para conte√∫do de redes sociais em ingl√™s.

---

## üîç Conceitos Importantes

### üìò O que √© BERT?

BERT (Bidirectional Encoder Representations from Transformers) √© um modelo de **linguagem natural bidirecional** desenvolvido pelo Google em 2018. Ele entende o **contexto completo** de uma palavra observando as palavras anteriores e posteriores. √â a base de muitos modelos de NLP atuais.

### üîÑ O que √© `transformers`?

A biblioteca `transformers` da Hugging Face oferece **modelos pr√©-treinados de NLP** com desempenho de ponta. Ela permite o uso f√°cil de modelos como BERT, RoBERTa, GPT, etc., com apenas poucas linhas de c√≥digo.

### üîå O que √© `pipeline`?

`pipeline` √© uma **interface de alto n√≠vel** da Hugging Face para executar tarefas como an√°lise de sentimentos, tradu√ß√£o, resumo, etc., com o m√≠nimo de configura√ß√£o.

---

## üì¶ Depend√™ncias

Para executar este projeto, voc√™ precisar√° instalar as seguintes bibliotecas:

```bash
pip install transformers emoji
```

> ‚ö†Ô∏è **Importante**: a biblioteca `transformers` requer um backend de deep learning para funcionar corretamente.
Voc√™ pode escolher entre **PyTorch** ou **TensorFlow**, dependendo da sua prefer√™ncia ou do modelo utilizado.

### ‚úÖ Instalar PyTorch (mais comum)

Para a maioria dos projetos e modelos, recomenda-se o uso do PyTorch:

```bash
pip install torch
```

Para op√ß√µes com suporte a GPU/CUDA, consulte o site oficial:  
üëâ https://pytorch.org/get-started/locally/

### üîÅ Alternativa: TensorFlow

Caso prefira usar TensorFlow como backend:

```bash
pip install tensorflow
```

Certifique-se de que o c√≥digo ou modelo que voc√™ est√° utilizando seja compat√≠vel com o backend escolhido.

---

Se voc√™ tentar rodar um pipeline do `transformers` sem ter o PyTorch ou TensorFlow instalados, um erro ser√° exibido informando que um backend √© necess√°rio.

## üß™ Ambiente Virtual

√â recomend√°vel usar um **ambiente virtual** para evitar conflitos entre depend√™ncias. Siga os passos:

### 1. Crie um ambiente virtual

```bash
python3 -m venv .venv
```

### 2. Ative o ambiente virtual

- **macOS e Linux**:

```bash
source .venv/bin/activate
```

- **Windows**:

```bash
.venv\Scripts\activate
```

---

## üñ•Ô∏è Exemplo de uso no terminal

### ‚úÖ Modelo 1:

```bash
python3 sentiment_analyzer.py
Modelos dispon√≠veis:
1 - nlptown/bert-base-multilingual-uncased-sentiment
2 - pysentimiento/robertuito-sentiment-analysis
3 - finiteautomata/bertweet-base-sentiment-analysis
****************************************************************************************************
Escolha o modelo (n√∫mero): 1
Device set to use mps:0
Digite o texto a ser analisado: A comida estava boa.
****************************************************************************************************
Texto: A comida estava boa.
Modelo usado: nlptown/bert-base-multilingual-uncased-sentiment
Classifica√ß√£o bruta: 4 stars
Score de confian√ßa: 0.38
Sentimento interpretado: positivo üôÇ
****************************************************************************************************
```

### ‚úÖ Modelo 2:

```bash
Escolha o modelo (n√∫mero): 2
Device set to use mps:0
Digite o texto a ser analisado: A comida estava boa.
****************************************************************************************************
Texto: A comida estava boa.
Modelo usado: pysentimiento/robertuito-sentiment-analysis
Classifica√ß√£o bruta: POS
Score de confian√ßa: 0.78
Sentimento interpretado: positivo üôÇ
****************************************************************************************************
```

### ‚úÖ Modelo 3:

```bash
Escolha o modelo (n√∫mero): 3
Device set to use mps:0
Digite o texto a ser analisado: The food was good.
****************************************************************************************************
Texto: The food was good.
Modelo usado: finiteautomata/bertweet-base-sentiment-analysis
Classifica√ß√£o bruta: POS
Score de confian√ßa: 0.99
Sentimento interpretado: positivo üôÇ
****************************************************************************************************
```

---

## üìö Documenta√ß√£o e Links √öteis

### üîß Bibliotecas e Ferramentas


- [PyTorch (Documenta√ß√£o Oficial)](https://pytorch.org/docs/) ‚Äî Biblioteca de aprendizado profundo amplamente usada como backend para `transformers`.
- [TensorFlow (Documenta√ß√£o Oficial)](https://www.tensorflow.org/learn) ‚Äî Alternativa ao PyTorch, tamb√©m compat√≠vel com `transformers`.

- [Transformers (Hugging Face)](https://huggingface.co/transformers/) ‚Äî Documenta√ß√£o oficial da biblioteca `transformers`, usada para criar pipelines como `sentiment-analysis`.  
  > ‚ö†Ô∏è Requer que **PyTorch** ou **TensorFlow** esteja instalado como backend para execu√ß√£o dos modelos.
- [emoji (Python Package)](https://pypi.org/project/emoji/) ‚Äî Biblioteca Python para manipula√ß√£o e visualiza√ß√£o de emojis.

### ü§ó Modelos Pr√©-Treinados para An√°lise de Sentimentos

- [nlptown/bert-base-multilingual-uncased-sentiment](https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment) ‚Äî Modelo BERT multilingue para classifica√ß√£o de sentimento em 5 n√≠veis (1 a 5 estrelas).
- [pysentimiento/robertuito-sentiment-analysis](https://huggingface.co/pysentimiento/robertuito-sentiment-analysis) ‚Äî Modelo baseado em RoBERTuito para sentimentos em espanhol (POS, NEU, NEG).
- [finiteautomata/bertweet-base-sentiment-analysis](https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis) ‚Äî Modelo baseado em BERTweet para an√°lise de sentimentos em ingl√™s (LABEL_0, LABEL_1, LABEL_2).

### üìÑ Artigos Relevantes

- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Google)](https://arxiv.org/abs/1810.04805) ‚Äî Artigo fundamental que introduz o modelo BERT, base para muitos modelos de NLP, incluindo os listados acima.

---

## üìö Sugest√£o de Leitura

**T√≠tulo:** *BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding*

**Autores:** Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova

**Tipo:** Artigo Cient√≠fico (Google AI)

**Link original:** [BERT Paper (arXiv)](https://arxiv.org/abs/1810.04805)

**Link local:** [BERT Paper (PDF)](Artigo_BERT/1810.04805v2.pdf)

**Resumo:** O BERT (Bidirectional Encoder Representations from Transformers) √© um modelo de linguagem pr√©-treinado profundamente bidirecional baseado na arquitetura Transformer. Ele foi projetado para compreender o contexto de uma palavra com base em todas as palavras em uma senten√ßa (tanto √† esquerda quanto √† direita). O BERT foi treinado em tarefas de modelagem de linguagem e previs√£o de frases, e depois ajustado em tarefas espec√≠ficas como perguntas e respostas, classifica√ß√£o de sentimentos e NER. Este artigo teve grande impacto no NLP moderno, redefinindo benchmarks em v√°rias tarefas.

**Palavras-chave:** NLP, Transformers, BERT, Google AI, Modelos de Linguagem

---

**T√≠tulo:** *Minera√ß√£o de Emo√ß√µes em Textos: Um Estudo Aplicado Sobre as Intera√ß√µes de Programadores em Comunidade On-line de Perguntas e Respostas*  

**Autor:** [Lucas Romualdo Fernandes de S√°](https://www.linkedin.com/in/lrfsa/)

**Tipo:** Disserta√ß√£o de Mestrado em Sistemas de Informa√ß√£o e Gest√£o do Conhecimento

**Link:** [Disserta√ß√£o (PDF)](DissertacÃßaÃÉo_Lucas_Romualdo_Fernandes_de_SaÃÅ/DISSERTACÃßAÃÉO_VERSAO_FINAL_REVISADA_LUCAS.pdf)

**Resumo:** O Stack Overflow √© a maior comunidade on-line de Perguntas-Respostas sobre Linguagem de Programa√ß√£o na Web, e sua import√¢ncia tem crescidopor causa do acumulo de t√≥picos relevantes para solu√ß√£o de problemas de Tecnologia da Informa√ß√£o (TI), disso a comunidade Stack Overflow tornou-se um reposit√≥rio de conhecimento, resultado de muitas intera√ß√µes sociais entre programadores e usu√°rios comuns. O Stack Overflow se tornou objeto de estudo e pesquisa em diferentes dom√≠nios de conhecimento, em paralelo, o campo de pesquisa de An√°lise de Sentimentos (AS) tamb√©m esteve em desenvolvimento e ascens√£o. Uma parte dos estudos realizados no campo de AS teve o Stack Overflow como objeto de pesquisa com intuito de entender se existe uma rela√ß√£o dos sentimentos, emo√ß√µes e opini√µes dos usu√°rios com as caracter√≠sticas e aspectos dessa comunidade on-line. O objetivo da pesquisa foi aplicar a an√°lise de sentimentos em posts de uma comunidade on-line de programa√ß√£o. A metodologia do trabalho adotou a realiza√ß√£o de uma Revisao Sistem√°tica da Literatura sobre o Stack Overflow e a aplica√ß√£o de recursos para AS fornecida pela linguagem R e seu pacote tidytext com os dicion√°rios l√©xicos NRC e AFINN em cima de coment√°rios de usu√°rios de diferentes linguagens de programa√ß√£o. Os resultados apresentaram a import√¢ncia de AS nas comunidades on-line e evidenciou como as tecnologias usadas pelo usu√°rio influenciam na padroniza√ß√£o do comportamento e tend√™ncia emocional dos usu√°rios. A conclus√£o apontou √† import√¢ncia de se apronfundar em estudos mais focados e estender tamb√©m o estudo a outras comunidades do Stack Exchange.

**Palavras-chaves:** An√°lise de Sentimentos, Minera√ß√£o de Emo√ß√£o, Stack Overflow.

---

## üìÑ Licen√ßa

Este projeto √© distribu√≠do sob a licen√ßa **MIT**. Voc√™ pode utiliz√°-lo, modific√°-lo e distribu√≠-lo livremente. üßë‚Äçüè´

---
