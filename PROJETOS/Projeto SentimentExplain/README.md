# ü§ñ Projeto SentimentExplain

## üéØ O que √© o projeto SentimentExplain?

SentimentExplain √© uma ferramenta em Python para an√°lise de sentimento que n√£o s√≥ classifica textos como positivos ou negativos, mas tamb√©m explica **por que** o modelo tomou aquela decis√£o.  
Ela utiliza t√©cnicas de interpretabilidade baseadas na biblioteca **LIME** para destacar as palavras que mais impactaram a predi√ß√£o, tornando o processo de an√°lise transparente e educativo.

---

## Sobre o modelo e tecnologias usadas

O projeto usa o modelo pr√©-treinado **distilbert-base-uncased-finetuned-sst-2-english** da Hugging Face.  
Esse modelo √© uma vers√£o leve do BERT (DistilBERT), treinada especificamente no dataset SST-2, um benchmark padr√£o para an√°lise de sentimento em ingl√™s. Ele classifica frases como POSITIVE ou NEGATIVE com alta precis√£o e rapidez.

Para facilitar o uso do modelo, o projeto utiliza o **pipeline** da biblioteca **transformers** da Hugging Face, que abstrai todo o pr√©-processamento, infer√™ncia e p√≥s-processamento, entregando um resultado simples e direto.

A explica√ß√£o das decis√µes do modelo √© feita com a biblioteca **LIME (Local Interpretable Model-agnostic Explanations)**, que cria explica√ß√µes locais interpret√°veis ao identificar quais palavras da frase mais influenciaram a classifica√ß√£o.  

O projeto gera um arquivo HTML interativo (`explanation.html`) que mostra a influ√™ncia de cada palavra, al√©m de imprimir no terminal o score (peso) dessas palavras ‚Äî indicando se elas contribuem positivamente ou negativamente para o sentimento previsto.

---

## üîç Conceitos Importantes

### üìò O que √© BERT?

BERT (Bidirectional Encoder Representations from Transformers) √© um modelo de **linguagem natural bidirecional** desenvolvido pelo Google em 2018. Ele entende o **contexto completo** de uma palavra observando as palavras anteriores e posteriores. √â a base de muitos modelos de NLP atuais.

### üîÑ O que √© `transformers`?

A biblioteca `transformers` da Hugging Face oferece **modelos pr√©-treinados de NLP** com desempenho de ponta. Ela permite o uso f√°cil de modelos como BERT, RoBERTa, GPT, etc., com apenas poucas linhas de c√≥digo.

### üîå O que √© `pipeline`?

`pipeline` √© uma **interface de alto n√≠vel** da Hugging Face para executar tarefas como an√°lise de sentimentos, tradu√ß√£o, resumo, etc., com o m√≠nimo de configura√ß√£o.

### üü¢ O que √© `LIME`?

`LIME` (*Local Interpretable Model-agnostic Explanations*) √© uma t√©cnica de **interpreta√ß√£o de modelos de machine learning**. Ela ajuda a entender **por que** um modelo tomou determinada decis√£o, destacando quais partes da entrada (como palavras em um texto) mais influenciaram o resultado.

No contexto deste projeto, o LIME mostra **as palavras que mais contribu√≠ram** para que o modelo previsse sentimento positivo ou negativo, tornando a IA **mais transparente e explic√°vel**. üîç

> LIME √© particularmente √∫til para modelos complexos (como redes neurais), que normalmente s√£o tratados como "caixas-pretas". Ele faz isso ao perturbar a entrada original e treinar modelos simples (como regress√£o linear) para simular o comportamento do modelo ao redor daquele exemplo.

---

## üñºÔ∏è Captura de tela

| <img src="https://joaopauloaramuni.github.io/python-imgs/SentimentExplain/imgs/html.png" alt="HTML" width="1000"/> |
|:---------------------------------------------------------------:|
|                        HTML explicativo                         |

---

## üì¶ Depend√™ncias

Para executar este projeto, voc√™ precisar√° instalar as seguintes bibliotecas:

```bash
pip install transformers torch lime
```

> ‚ö†Ô∏è **Importante**: a biblioteca `transformers` requer um backend de deep learning para funcionar corretamente.  
Voc√™ pode escolher entre **PyTorch** ou **TensorFlow**, dependendo da sua prefer√™ncia ou do modelo utilizado.

### ‚úÖ Instalar PyTorch (mais comum)

Para a maioria dos projetos e modelos, recomenda-se o uso do PyTorch:

```bash
pip install torch
```

Para op√ß√µes com suporte a GPU/CUDA, consulte o site oficial:  
üëâ https://pytorch.org/get-started/locally/

### üîÅ Alternativa: TensorFlow

Caso prefira usar TensorFlow como backend:

```bash
pip install tensorflow
```

Certifique-se de que o c√≥digo ou modelo que voc√™ est√° utilizando seja compat√≠vel com o backend escolhido.

---

Se voc√™ tentar rodar um pipeline do `transformers` sem ter o PyTorch ou TensorFlow instalados, um erro ser√° exibido informando que um backend √© necess√°rio.

## üß™ Ambiente Virtual

√â recomend√°vel usar um **ambiente virtual** para evitar conflitos entre depend√™ncias. Siga os passos:

### 1. Crie um ambiente virtual

```bash
python3 -m venv .venv
```

### 2. Ative o ambiente virtual

- **macOS e Linux**:

```bash
source .venv/bin/activate
```

- **Windows**:

```bash
.venv\Scripts\activate
```

---

## üñ•Ô∏è Exemplo de uso no terminal

### ‚úÖ Modelo 1:

```bash
(.venv) (base) joaopauloaramuni@MacBook-Pro-de-Joao Projeto SentimentExplain % python3 sentiment_explain.py
No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).
Using a pipeline without specifying a model name and revision in production is not recommended.
Device set to use mps:0
******************************************************************************************************************************************************
Digite uma frase para analisar: The food was good.
Texto: The food was good.

Sentimento previsto: POSITIVE (confian√ßa 1.00)

Explica√ß√£o das palavras que mais impactaram a decis√£o:

good: 0.0405
food: 0.0393
was: -0.0020
The: 0.0008
******************************************************************************************************************************************************
```

## üìö Documenta√ß√£o e Links √öteis

### üîß Bibliotecas e Ferramentas


- [PyTorch (Documenta√ß√£o Oficial)](https://pytorch.org/docs/) ‚Äî Biblioteca de aprendizado profundo amplamente usada como backend para `transformers`.
- [TensorFlow (Documenta√ß√£o Oficial)](https://www.tensorflow.org/learn) ‚Äî Alternativa ao PyTorch, tamb√©m compat√≠vel com `transformers`.

- [Transformers (Hugging Face)](https://huggingface.co/transformers/) ‚Äî Documenta√ß√£o oficial da biblioteca `transformers`, usada para criar pipelines como `sentiment-analysis`.  
  > ‚ö†Ô∏è Requer que **PyTorch** ou **TensorFlow** esteja instalado como backend para execu√ß√£o dos modelos.

### ü§ó Modelo Pr√©-Treinado para An√°lise de Sentimentos

- [distilbert-base-uncased-finetuned-sst-2-english](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english) - Modelo baseado no DistilBERT, treinado especificamente para an√°lise de sentimentos usando o dataset SST-2 (Stanford Sentiment Treebank). Ele √© uma vers√£o mais leve e r√°pida do BERT, ideal para tarefas de NLP com bom desempenho e efici√™ncia.

### üìÑ Artigos Relevantes

- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Google)](https://arxiv.org/abs/1810.04805) ‚Äî Artigo fundamental que introduz o modelo BERT, base para muitos modelos de NLP, incluindo os listados acima.

---

## üìö Sugest√£o de Leitura

**T√≠tulo:** *BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding*

**Autores:** Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova

**Tipo:** Artigo Cient√≠fico (Google AI)

**Link original:** [BERT Paper (arXiv)](https://arxiv.org/abs/1810.04805)

**Link local:** [BERT Paper (PDF)](Artigo_BERT/1810.04805v2.pdf)

**Resumo:** O BERT (Bidirectional Encoder Representations from Transformers) √© um modelo de linguagem pr√©-treinado profundamente bidirecional baseado na arquitetura Transformer. Ele foi projetado para compreender o contexto de uma palavra com base em todas as palavras em uma senten√ßa (tanto √† esquerda quanto √† direita). O BERT foi treinado em tarefas de modelagem de linguagem e previs√£o de frases, e depois ajustado em tarefas espec√≠ficas como perguntas e respostas, classifica√ß√£o de sentimentos e NER. Este artigo teve grande impacto no NLP moderno, redefinindo benchmarks em v√°rias tarefas.

**Palavras-chave:** NLP, Transformers, BERT, Google AI, Modelos de Linguagem

---

**T√≠tulo:** *Minera√ß√£o de Emo√ß√µes em Textos: Um Estudo Aplicado Sobre as Intera√ß√µes de Programadores em Comunidade On-line de Perguntas e Respostas*  

**Autor:** [Lucas Romualdo Fernandes de S√°](https://www.linkedin.com/in/lrfsa/)

**Tipo:** Disserta√ß√£o de Mestrado em Sistemas de Informa√ß√£o e Gest√£o do Conhecimento

**Link:** [Disserta√ß√£o (PDF)](DissertacÃßaÃÉo_Lucas_Romualdo_Fernandes_de_SaÃÅ/DISSERTACÃßAÃÉO_VERSAO_FINAL_REVISADA_LUCAS.pdf)

**Resumo:** O Stack Overflow √© a maior comunidade on-line de Perguntas-Respostas sobre Linguagem de Programa√ß√£o na Web, e sua import√¢ncia tem crescidopor causa do acumulo de t√≥picos relevantes para solu√ß√£o de problemas de Tecnologia da Informa√ß√£o (TI), disso a comunidade Stack Overflow tornou-se um reposit√≥rio de conhecimento, resultado de muitas intera√ß√µes sociais entre programadores e usu√°rios comuns. O Stack Overflow se tornou objeto de estudo e pesquisa em diferentes dom√≠nios de conhecimento, em paralelo, o campo de pesquisa de An√°lise de Sentimentos (AS) tamb√©m esteve em desenvolvimento e ascens√£o. Uma parte dos estudos realizados no campo de AS teve o Stack Overflow como objeto de pesquisa com intuito de entender se existe uma rela√ß√£o dos sentimentos, emo√ß√µes e opini√µes dos usu√°rios com as caracter√≠sticas e aspectos dessa comunidade on-line. O objetivo da pesquisa foi aplicar a an√°lise de sentimentos em posts de uma comunidade on-line de programa√ß√£o. A metodologia do trabalho adotou a realiza√ß√£o de uma Revisao Sistem√°tica da Literatura sobre o Stack Overflow e a aplica√ß√£o de recursos para AS fornecida pela linguagem R e seu pacote tidytext com os dicion√°rios l√©xicos NRC e AFINN em cima de coment√°rios de usu√°rios de diferentes linguagens de programa√ß√£o. Os resultados apresentaram a import√¢ncia de AS nas comunidades on-line e evidenciou como as tecnologias usadas pelo usu√°rio influenciam na padroniza√ß√£o do comportamento e tend√™ncia emocional dos usu√°rios. A conclus√£o apontou √† import√¢ncia de se apronfundar em estudos mais focados e estender tamb√©m o estudo a outras comunidades do Stack Exchange.

**Palavras-chaves:** An√°lise de Sentimentos, Minera√ß√£o de Emo√ß√£o, Stack Overflow.

---

## üìÑ Licen√ßa

Este projeto √© distribu√≠do sob a licen√ßa **MIT**. Voc√™ pode utiliz√°-lo, modific√°-lo e distribu√≠-lo livremente. üßë‚Äçüè´
